{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from schema import HIGH_PERFORMER_COL\n","from schema import INDEX_COL\n","from schema import PREDICTOR_COLS\n","from schema import PROTECTED_GROUP_COL\n","from schema import RETAINED_COL\n","from schema import TARGET_COLS\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","from xgboost import XGBClassifier\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Extracting targets and predictors from train.csv"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["predictor_cols = list(PREDICTOR_COLS)\n","target_cols = list(TARGET_COLS)\n","usecols = [INDEX_COL] + target_cols + predictor_cols\n","train = pd.read_csv(\n","    \"../data/train.csv\",\n","    index_col=\"UNIQUE_ID\",\n","    usecols=usecols,\n","    na_values=\" \",\n",")\n","train.dropna(subset=target_cols, inplace=True)\n","\n","X = train[predictor_cols]\n","y = train[target_cols]\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Adding derived targets\n"," 1. _High performer retained_ candidates who are high performers and\n"," retained\n"," 2. _Exclusive retained_ candidates that are only retained\n"," 3. _Exclusive high performer_ candidates that are only high performer"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["high_performer_retained_col = f\"{HIGH_PERFORMER_COL}_{RETAINED_COL}\"\n","y[high_performer_retained_col] = y.apply(\n","    lambda row: int(row[HIGH_PERFORMER_COL] > 0 and row[RETAINED_COL] > 0),\n","    axis=1,\n",")\n","target_cols.append(high_performer_retained_col)\n","\n","exclusive_retained_col = f\"Exclusive_{RETAINED_COL}\"\n","y[exclusive_retained_col] = y.apply(\n","    lambda row: int(row[HIGH_PERFORMER_COL] < 1 and row[RETAINED_COL] > 0),\n","    axis=1,\n",")\n","target_cols.append(exclusive_retained_col)\n","\n","exclusive_high_performer = f\"Exclusive_{HIGH_PERFORMER_COL}\"\n","y[exclusive_high_performer] = y.apply(\n","    lambda row: int(row[HIGH_PERFORMER_COL] > 0 and row[RETAINED_COL] < 1),\n","    axis=1,\n",")\n","target_cols.append(exclusive_high_performer)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Pipeline and training"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["estimator = XGBClassifier(\n","    objective=\"binary:logistic\",\n","    eval_metric=\"logloss\",\n","    n_estimators=1000,\n","    learning_rate=0.05,\n","    n_jobs=4,\n",")\n","model = OneVsRestClassifier(estimator)\n","\n","pipeline = Pipeline(\n","    steps=[\n","        (\"imputer\", SimpleImputer()),\n","        (\"scaler\", StandardScaler()),\n","        (\"model\", model),\n","    ],\n",")\n","pipeline.fit(X_train, y_train)\n","y_proba = pipeline.predict_proba(X_test)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Evaluation"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["High_Performer\n--------------\naccuracy: 0.6032953105196451\nconfusion matrix:\n[[373 103]\n [210 103]]\n\nProtected_Group\n---------------\naccuracy: 0.6945500633713562\nconfusion matrix:\n[[428  76]\n [165 120]]\n\nRetained\n--------\naccuracy: 0.5449936628643853\nconfusion matrix:\n[[100 234]\n [125 330]]\n\nHigh_Performer_Retained\n-----------------------\naccuracy: 0.7173637515842839\nconfusion matrix:\n[[552  37]\n [186  14]]\n\nExclusive_Retained\n------------------\naccuracy: 0.6679340937896071\nconfusion matrix:\n[[478  56]\n [206  49]]\n\nExclusive_High_Performer\n------------------------\naccuracy: 0.85297845373891\nconfusion matrix:\n[[673   3]\n [113   0]]\n\n"]}],"source":["y_pred = y_proba > 0.5\n","for idx, target in enumerate(target_cols):\n","    print(f\"{target}\")\n","    print(\"-\" * len(target))\n","    print(f\"accuracy: {accuracy_score(y_test[target], y_pred[:, idx])}\")\n","    print(f\"confusion matrix:\\n{confusion_matrix(y_test[target], y_pred[:, idx])}\")\n","    print()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Ranking hires based on predictions and heuristic"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# This heuristic is based on the actual scoring mechanism\n","hr_scores = np.zeros((y_proba.shape[0]))\n","hr_scores = (\n","    hr_scores[:] + 0.25 * y_proba[:, 0] + 0.25 * y_proba[:, 2] + 0.5 * y_proba[:, 3]\n",")\n","hr_scores = hr_scores[:] + 0.1 * y_proba[:, 1]\n","\n","hr_score_col = \"HR_SCORE\"\n","y_hired = y_test.copy()\n","y_hired[hr_score_col] = hr_scores\n","y_hired.sort_values(by=[hr_score_col], ascending=False, inplace=True)\n","y_hired = y_hired.head(y_hired.shape[0] // 2)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Final score"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["ratio protected hired: 0.49473684210526314\nratio privilegded hired: 0.501984126984127\nadverse impact ratio: 0.9855627210318285\nunfairness: 1.4437278968171485\nratio true high performer: 0.5718849840255591\nratio true retained: 0.4967032967032967\nratio true high performer retained: 0.57\nfinal score: 53.77097912140424\n"]}],"source":["def extract_counts(split):  # noqa: E302\n","    thp_count = split[split[HIGH_PERFORMER_COL] == 1.0].shape[0]\n","    tr_count = split[split[RETAINED_COL] == 1.0].shape[0]\n","    thpr_count = split[\n","        (split[HIGH_PERFORMER_COL] == 1.0) & (split[RETAINED_COL] == 1.0)\n","    ].shape[0]\n","    pro_count = split[split[PROTECTED_GROUP_COL] == 1.0].shape[0]\n","    priv_count = split[split[PROTECTED_GROUP_COL] == 0.0].shape[0]\n","    return (thp_count, tr_count, thpr_count, pro_count, priv_count)\n","\n","\n","(\n","    thp_count_hired,\n","    tr_count_hired,\n","    thpr_count_hired,\n","    pro_count_hired,\n","    priv_count_hired,\n",") = extract_counts(y_hired)\n","\n","(\n","    thp_count_test,\n","    tr_count_test,\n","    thpr_count_test,\n","    pro_count_test,\n","    priv_count_test,\n",") = extract_counts(y_test)\n","\n","\"\"\"\n","Final_score = Overall_accuracy â€“ Unfairness\n","\n","Overall_accuracy=\n","Percentage_of_true_top_performers_hired * 25+\n","Percentage_of_true_retained_hired * 25 +\n","Percentage_of_true_retained_top_perf_hired * 50\n","\n","Unfairness = Absolute_value(1 - Adverse_impact_ratio) * 100\n","\"\"\"\n","ratio_pro = pro_count_hired / pro_count_test\n","print(f\"ratio protected hired: {ratio_pro}\")\n","\n","ratio_priv = priv_count_hired / priv_count_test\n","print(f\"ratio privilegded hired: {ratio_priv}\")\n","\n","adverse_impact_ratio = ratio_pro / ratio_priv\n","print(f\"adverse impact ratio: {adverse_impact_ratio}\")\n","\n","unfairness = abs(1.0 - adverse_impact_ratio) * 100\n","print(f\"unfairness: {unfairness}\")\n","\n","ratio_thp = thp_count_hired / thp_count_test\n","print(f\"ratio true high performer: {ratio_thp}\")\n","\n","ratio_tr = tr_count_hired / tr_count_test\n","print(f\"ratio true retained: {ratio_tr}\")\n","\n","ratio_thpr = thpr_count_hired / thpr_count_test\n","print(f\"ratio true high performer retained: {ratio_thpr}\")\n","\n","final_score = (\n","    25 * ratio_thp\n","    + 25 * ratio_tr\n","    + 50 * ratio_thpr\n","    - unfairness\n",")\n","print(f\"final score: {final_score}\")\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}
